#!/usr/bin/env bash
#
# git@github.com:evilneuro/petition-241584/bin/grab
# Collect a JSON data file of signatures and related petition metadata
#
# (c) 2019 William Anderson <neuro@well.com>

PETITIONS_DIR=~/petitions
JO_CLI_COMMAND="/usr/bin/jo"
JQ_CLI_COMMAND="/usr/local/bin/jq"

if [ ! -d ${PETITIONS_DIR} ]; then echo "$(basename ${0}): where is ${PETITIONS_DIR}" >&2; exit 1; fi
if [ ! -x $JO_CLI_COMMAND ]; then echo "$(basename $0): can't find jo" >&2; exit 1; fi
if [ ! -x $JQ_CLI_COMMAND ]; then echo "$(basename $0): can't find jq" >&2; exit 1; fi

function usage() {
	echo -e "usage: $(basename ${0}) -p [PETITION ID]"
	exit 1
}

while getopts "hp:" CLI_OPTIONS
do
	case ${CLI_OPTIONS} in
		h)
			usage
			exit 0
			;;
		p)
			PETITION_ID=${OPTARG}
			;;
		*)
			echo "$(basename ${0}): option '-${OPTARG}' is not supported" >&2
			usage
			;;
	esac
done

if [ "${PETITION_ID}" == "" ]; then echo "$(basename $0): need a petition ID (-p XXXXX)" >&2; exit 1; fi

# rock into the petition dir and make sure we're all up to date, because
# scripts always be changin'
cd ${PETITIONS_DIR} && git pull >/dev/null 2>&1
# get the name of the last changed datafile (we have loads already, so there's no need
# to put safegaurds in here to check for "oh no there's no files" etc.)
DATAFILE_LAST=$(ls -1 json/${PETITION_ID}-*.json | tail -1)
# generate the name of the file we're going to download, and potentially keep
DATAFILE_THIS=json/${PETITION_ID}-$(date +"%Y%m%d-%H%M").json
# grab that juicy json shizzle, which is published under an Open Government Licence
# and this data is used and republished under the terms of that licence
# https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/
curl --silent --retry 10 --retry-delay 15 https://petition.parliament.uk/petitions/${PETITION_ID}.json 2>/dev/null | ${JQ_CLI_COMMAND} . > ${DATAFILE_THIS} 2>/dev/null
# if what we just downloaded has no 'updated_at' field, something went wrong
if [ "$(cat ${DATAFILE_THIS} | ${JQ_CLI_COMMAND} -r '.data.attributes.updated_at')" == "" ]
then
	rm -f ${DATAFILE_THIS} >/dev/null
	exit 1
# if what we just downloaded has an 'updated_at' field, let's see if it
# matches what we downloaded previously
elif [ "$(cat ${DATAFILE_LAST} | jq -r '.data.attributes.updated_at')" == "$(cat ${DATAFILE_THIS} | ${JQ_CLI_COMMAND} -r '.data.attributes.updated_at')" ]
then
	# if it is identical, bin what we just downloaded, it's of no use to us
	rm -f ${DATAFILE_THIS} >/dev/null
fi
# do a build of the summary timeline JSON file
bash bin/build -p ${PETITION_ID}
# symlink to latest data file
ln -sf $(ls -1tr json/${PETITION_ID}-*.json | tail -1) petition_data.json
# whatever's left, let's commit it to git
git add . >/dev/null 2>&1 && git commit -am "[auto] $(date +'%Y%m%d%H%M%Z') $(basename ${0}) on ${HOSTNAME} by $(whoami)" >/dev/null 2>&1 && git push origin master >/dev/null 2>&1
# we're done; LET'S GET THE HELL OUT OF HERE ... but let's NOT get out of the EU
# do you see what I did there?
